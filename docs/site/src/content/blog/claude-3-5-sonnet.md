---
slug: "claude-3-5-sonnet"
title: "Claude 3.5 Sonnet: When the Mid-Tier Outperformed the Flagship"
description: "Claude 3.5 Sonnet launched June 2024 and outperformed the larger Claude 3 Opus on most benchmarks. A mid-tier model that redefined expectations."
date: "2024-06-20"
author: "Max Ritter"
tags: [Reference, Models]
readingTime: 3
keywords: "3, 35, 5, claude, flagship, midtier, outperformed, sonnet, when"
---

# Claude 3.5 Sonnet: When the Mid-Tier Outperformed the Flagship

Claude 3.5 Sonnet launched June 2024 and outperformed the larger Claude 3 Opus on most benchmarks. A mid-tier model that redefined expectations.

Claude 3.5 Sonnet proved that bigger is not always better. Released June 20, 2024, this mid-tier model outperformed the larger, more expensive Claude 3 Opus on most benchmarks while costing 80% less. It was the moment developers stopped assuming that the flagship model was automatically the best choice.

## [Key Specs](#key-specs)

| Spec | Details |
| --- | --- |
| **API ID** | `claude-3-5-sonnet-20240620` |
| **Context window** | 200K tokens |
| **Input pricing** | $3 / 1M tokens |
| **Output pricing** | $15 / 1M tokens |
| **Release date** | June 20, 2024 |
| **Max output tokens** | 8,192 |

## [What Claude 3.5 Sonnet Brought to the Table](#what-claude-35-sonnet-brought-to-the-table)

**Flagship intelligence at mid-tier pricing.** Claude 3.5 Sonnet matched or exceeded Claude 3 Opus across graduate-level reasoning (GPQA), undergraduate knowledge (MMLU), and coding (HumanEval). It did this at $3/$15 per million tokens instead of $15/$75. The cost-performance ratio was unprecedented.

**Coding strength.** This was the model that made Claude a serious coding tool. It solved 64% of problems on HumanEval, up from Opus's 55%. Developers who had been using GPT-4 for code started switching. The combination of reasoning quality and code output made it the default for software engineering tasks.

**Speed.** Claude 3.5 Sonnet operated at roughly twice the speed of Claude 3 Opus. For interactive coding sessions, chat applications, and any latency-sensitive workflow, the speed improvement was immediately noticeable.

**The "Sonnet is enough" realization.** Before this release, the assumption was simple: harder problem, bigger model. Claude 3.5 Sonnet broke that pattern. Teams that had been paying for Opus discovered they could get equal or better results from Sonnet at a fifth of the price. This shift in thinking influenced how developers approached [model selection](/blog/models/model-selection) going forward.

## [How It Compared to Claude 3 Opus](#how-it-compared-to-claude-3-opus)

| Benchmark | Claude 3 Opus | Claude 3.5 Sonnet |
| --- | --- | --- |
| MMLU | 86.8% | 88.7% |
| GPQA | 50.4% | 59.4% |
| HumanEval | 55% | 64% |
| GSM8K | 95.0% | 96.4% |

Higher scores across the board, at one-fifth the cost. The numbers made the case on their own.

## [What About Claude 3.5 Opus?](#what-about-claude-35-opus)

Anthropic announced a Claude 3.5 Opus during the 3.5 Sonnet launch. It never shipped. The Claude 4 generation superseded the entire 3.5 line before a larger 3.5 model was needed. Given how well Sonnet performed, the market pressure for a 3.5 Opus simply never materialized.

## [Current Status](#current-status)

| Model | Status |
| --- | --- |
| Claude 3.5 Sonnet (v1) | Superseded by v2 (October 2024) |

The original 3.5 Sonnet was replaced by an [upgraded version in October 2024](/blog/models/claude-3-5-sonnet-v2) that brought further improvements and the groundbreaking Computer Use feature.

## [Navigation](#navigation)

- [All Claude Models](/blog/models) for the complete model index
- [Claude 3](/blog/models/claude-3), the predecessor family
- [Claude 3.5 Sonnet v2](/blog/models/claude-3-5-sonnet-v2), the October 2024 upgrade with Computer Use

Last updated on

[Previous

Claude 3.5 Sonnet v2](/blog/models/claude-3-5-sonnet-v2)[Next

Claude 3](/blog/models/claude-3)
